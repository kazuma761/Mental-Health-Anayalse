{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21dffc8a-a9f3-4449-9578-1dd9fbdd21d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.1-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-2.1.1-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2b5d58-8a1c-4d7b-ba93-3cf3d6c40ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cd2708b-2166-49db-b1c7-2e878c18e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e74c2d9-bd75-4278-a775-43b2fe10eaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('merged_output.csv')\n",
    "\n",
    "# Load positive and depressed words\n",
    "with open('positive-words.txt', 'r') as file:\n",
    "    positive_words = set(file.read().splitlines())\n",
    "\n",
    "with open('depressedword.txt', 'r') as file:\n",
    "    depressed_words = set(file.read().splitlines())\n",
    "\n",
    "# Function to label the sentiment\n",
    "def label_sentiment(text):\n",
    "    words = set(text.lower().split())\n",
    "    positive_count = len(words.intersection(positive_words))\n",
    "    depressed_count = len(words.intersection(depressed_words))\n",
    "    \n",
    "    if depressed_count > positive_count:\n",
    "        return 2  # Depressed\n",
    "    elif positive_count > 0:\n",
    "        return 1  # Positive\n",
    "    else:\n",
    "        return 0  # Neutral/Negative\n",
    "\n",
    "# Create labels based on word counts\n",
    "df['label'] = df['content'].apply(label_sentiment)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text\n",
    "max_words = 670000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0850a187-36ea-4903-9da9-67ce9289952c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'le' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_train_encoded \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(y_train)\n\u001b[1;32m      2\u001b[0m y_test_encoded \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(y_test)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create TF-IDF features\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'le' is not defined"
     ]
    }
   ],
   "source": [
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# Create TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "print(\"Random Forest Classifier Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_encoded, rf_predictions))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, rf_predictions))\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "# Make predictions\n",
    "xgb_predictions = xgb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate XGBoost model\n",
    "print(\"\\nXGBoost Classifier Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_encoded, xgb_predictions))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, xgb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a29bf9-777b-4a3b-8fe7-e43b66dc0278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a88fe1b-72e8-43a2-a99f-82f49b6a5f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('merged_output.csv')\n",
    "\n",
    "# Load positive and depressed words\n",
    "with open('positive-words.txt', 'r') as file:\n",
    "    positive_words = set(file.read().splitlines())\n",
    "\n",
    "with open('depressedword.txt', 'r') as file:\n",
    "    depressed_words = set(file.read().splitlines())\n",
    "\n",
    "# Function to label the sentiment\n",
    "def label_sentiment(text):\n",
    "    words = set(text.lower().split())\n",
    "    positive_count = len(words.intersection(positive_words))\n",
    "    depressed_count = len(words.intersection(depressed_words))\n",
    "    \n",
    "    if depressed_count > positive_count:\n",
    "        return 2  # Depressed\n",
    "    elif positive_count > 0:\n",
    "        return 1  # Positive\n",
    "    else:\n",
    "        return 0  # Neutral/Negative\n",
    "\n",
    "# Create labels based on word counts\n",
    "df['label'] = df['content'].apply(label_sentiment)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=670000, stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61e13938-c302-492d-bf96-280409a08e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      2032\n",
      "           1       0.95      0.81      0.88      1026\n",
      "           2       0.93      0.52      0.67       362\n",
      "\n",
      "    accuracy                           0.89      3420\n",
      "   macro avg       0.92      0.78      0.82      3420\n",
      "weighted avg       0.90      0.89      0.88      3420\n",
      "\n",
      "Accuracy: 0.8891812865497076\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "# Predictions\n",
    "rf_predictions = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest Classifier Report:\")\n",
    "print(classification_report(y_test_encoded, rf_predictions))\n",
    "print(f\"Accuracy: {accuracy_score(y_test_encoded, rf_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "809d207c-53fe-497f-a65c-be8c9aa80c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:57:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92      2032\n",
      "           1       0.97      0.78      0.86      1026\n",
      "           2       0.91      0.51      0.65       362\n",
      "\n",
      "    accuracy                           0.88      3420\n",
      "   macro avg       0.91      0.76      0.81      3420\n",
      "weighted avg       0.89      0.88      0.87      3420\n",
      "\n",
      "Accuracy: 0.8809941520467837\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# XGBoost Classifier\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_model.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "# Predictions\n",
    "xgb_predictions = xgb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "print(\"XGBoost Classifier Report:\")\n",
    "print(classification_report(y_test_encoded, xgb_predictions))\n",
    "print(f\"Accuracy: {accuracy_score(y_test_encoded, xgb_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d202831-84e1-4334-bdd3-a0c8d90bc6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fffa5-139f-4fcd-a7aa-8a506373526a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30545aa0-f4b6-400c-b7a5-a863a0c54591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c5c549-b192-46dc-a62e-161827cc1d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac367e58-6f3e-4408-8bcb-c27e6a525260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f3fd9f-b470-40c1-a751-21bb1d1374c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62cd1a-00ca-4123-88a3-8dbafab460fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a6c43f7-edca-48d1-914a-337df74eb4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:59:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92      2032\n",
      "           1       0.97      0.80      0.88      1026\n",
      "           2       0.92      0.53      0.67       362\n",
      "\n",
      "    accuracy                           0.89      3420\n",
      "   macro avg       0.92      0.78      0.82      3420\n",
      "weighted avg       0.90      0.89      0.88      3420\n",
      "\n",
      "Accuracy: 0.8900584795321638\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('merged_output.csv')\n",
    "\n",
    "# Load positive and depressed words\n",
    "with open('positive-words.txt', 'r') as file:\n",
    "    positive_words = set(file.read().splitlines())\n",
    "\n",
    "with open('depressedword.txt', 'r') as file:\n",
    "    depressed_words = set(file.read().splitlines())\n",
    "\n",
    "# Function to label the sentiment\n",
    "def label_sentiment(text):\n",
    "    words = set(text.lower().split())\n",
    "    positive_count = len(words.intersection(positive_words))\n",
    "    depressed_count = len(words.intersection(depressed_words))\n",
    "    \n",
    "    if depressed_count > positive_count:\n",
    "        return 2  # Depressed\n",
    "    elif positive_count > 0:\n",
    "        return 1  # Positive\n",
    "    else:\n",
    "        return 0  # Neutral/Negative\n",
    "\n",
    "# Create labels based on word counts\n",
    "df['label'] = df['content'].apply(label_sentiment)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=670000, stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# Define the classifiers\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Create a Voting Classifier\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('rf', rf_model),\n",
    "    ('xgb', xgb_model)\n",
    "], voting='soft')  # 'soft' voting uses predicted probabilities\n",
    "\n",
    "# Fit the Voting Classifier\n",
    "voting_model.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "# Predictions from the Voting Classifier\n",
    "voting_predictions = voting_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the Voting Classifier\n",
    "print(\"Voting Classifier Report:\")\n",
    "print(classification_report(y_test_encoded, voting_predictions))\n",
    "print(f\"Accuracy: {accuracy_score(y_test_encoded, voting_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba0405-d1fc-412b-8c00-754cdb61e920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5197e3b-f65e-4aba-acea-85d52a7bea00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1b108a6-788f-4ef5-858e-6809c04c567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:59:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [16:00:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [16:00:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [16:00:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [16:00:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.93      2032\n",
      "           1       0.94      0.83      0.88      1026\n",
      "           2       0.90      0.65      0.75       362\n",
      "\n",
      "    accuracy                           0.90      3420\n",
      "   macro avg       0.91      0.82      0.86      3420\n",
      "weighted avg       0.91      0.90      0.90      3420\n",
      "\n",
      "Accuracy: 0.9038011695906433\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('rf', rf_model),\n",
    "    ('xgb', xgb_model)\n",
    "]\n",
    "\n",
    "# Define the meta model (Logistic Regression in this case)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create a Stacking Classifier\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Fit the Stacking Classifier\n",
    "stacking_model.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "# Predictions from the Stacking Classifier\n",
    "stacking_predictions = stacking_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the Stacking Classifier\n",
    "print(\"Stacking Classifier Report:\")\n",
    "print(classification_report(y_test_encoded, stacking_predictions))\n",
    "print(f\"Accuracy: {accuracy_score(y_test_encoded, stacking_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530ec34-b83c-473d-8746-2c00240f7274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
